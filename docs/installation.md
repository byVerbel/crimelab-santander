# InstalaciÃ³n

GuÃ­a para configurar el entorno de desarrollo del proyecto.

## Requisitos previos

- Python 3.12 o superior
- `pip` (incluido con Python)
- `git` para clonar el repositorio

## Pasos de instalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/aluribes/Datos-al-Ecosistema.git
cd Datos-al-Ecosistema
```

### 2. Crear entorno virtual

Se recomienda usar un entorno virtual para aislar las dependencias del proyecto.

```bash
python3 -m venv .venv
```

Activar el entorno:

```bash
# Linux / macOS
source .venv/bin/activate

# Windows
.venv\Scripts\activate
```

> ðŸ’¡ SabrÃ¡s que el entorno estÃ¡ activo cuando veas `(.venv)` al inicio de tu terminal.

### 3. Instalar dependencias

```bash
# Linux / macOS
source setup.sh

# Windows
setup
```

### 4. Dependencias del sistema (macOS)

En **macOS**, XGBoost requiere la librerÃ­a OpenMP para funcionar. Si al importar `xgboost` obtienes un error como:

```
XGBoost Library (libxgboost.dylib) could not be loaded.
Likely causes: OpenMP runtime is not installed
```

Instala OpenMP con Homebrew:

```bash
brew install libomp
```

> ðŸ’¡ Esto no es necesario en Linux (ya incluye `libgomp`) ni en Windows.

---

## EjecuciÃ³n del Pipeline

El pipeline sigue una arquitectura medallion (Bronze â†’ Silver â†’ Gold â†’ Model). Ejecutar los scripts en el orden indicado.

### SecciÃ³n 00 â€” Setup

```bash
python scripts/00_setup.py
```

Crea la estructura de carpetas `data/bronze`, `data/silver`, `data/gold`.

### SecciÃ³n 01 â€” Bronze (ExtracciÃ³n)

```bash
python scripts/01_extract_bronze.py
python scripts/01_scrape_policia_estadistica.py
python scripts/01_generate_polygon_santander.py
```

**Nota:** Debes descargar manualmente los archivos ZIP de poblaciÃ³n DANE en `data/bronze/poblacion_dane/`.

### SecciÃ³n 02 â€” Silver (Limpieza)

```bash
python scripts/02_process_danegeo.py
python scripts/02_process_socrata.py
python scripts/02_socrata_bucaramanga_to_parquet.py
python scripts/02_process_policia.py
python scripts/02_process_policia_completo.py
python scripts/02_datos_poblacion_santander.py
python scripts/02_extract_metas.py
```

### SecciÃ³n 03 â€” Gold (IntegraciÃ³n)

```bash
python scripts/03_process_silver_data.py
python scripts/03_generate_gold.py
```

### SecciÃ³n 04 â€” Model Data (PreparaciÃ³n ML)

```bash
# Analytics y Dashboard
python scripts/04_generate_analytics.py
python scripts/04_generate_dashboard_data.py

# Datasets para modelos
python scripts/04_generate_regression_monthly_dataset.py
python scripts/04_generate_regression_annual_dataset.py
python scripts/04_generate_regression_timeseries_dataset.py
python scripts/04_generate_classification_monthly_dataset.py
python scripts/04_generate_classification_event_dataset.py
python scripts/04_generate_classification_dominant_dataset.py
python scripts/04_generate_clustering_geo_dataset.py
```

---

## Estructura del proyecto

Una vez instalado, la estructura principal es:

```
Datos-al-Ecosistema/
â”œâ”€â”€ data/                 # Datos (bronze, silver, gold)
â”‚   â”œâ”€â”€ bronze/           # Datos crudos
â”‚   â”œâ”€â”€ silver/           # Datos limpios
â”‚   â””â”€â”€ gold/             # Datos integrados + model datasets
â”œâ”€â”€ scripts/              # Pipeline de procesamiento
â”œâ”€â”€ notebooks/            # Notebooks de anÃ¡lisis y modelado
â”œâ”€â”€ models/               # Modelos entrenados (.joblib, .json)
â”œâ”€â”€ docs/                 # DocumentaciÃ³n
â”‚   â”œâ”€â”€ pipeline/         # Docs por secciÃ³n (00-04)
â”‚   â””â”€â”€ dashboard_chatbot_models/  # Docs para chatbot
â”œâ”€â”€ requirements.txt      # Dependencias
â”œâ”€â”€ setup.bat             # ConfiguraciÃ³n en Windows
â”œâ”€â”€ setup.sh              # ConfiguraciÃ³n en Linux o MacOS
â””â”€â”€ app.py                # AplicaciÃ³n Streamlit
```

## Siguiente paso

Consulta la documentaciÃ³n del pipeline en [`docs/pipeline/`](pipeline/) para entender el detalle de cada script.
